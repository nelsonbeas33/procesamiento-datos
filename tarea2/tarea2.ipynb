{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZfDa40ZoQEzaXj0UTy6KI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelsonbeas33/procesamiento-datos/blob/main/tarea2/tarea2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhRLTA9_Yf_V",
        "outputId": "2ed1373e-a6dd-4166-f2c3-953d4c5d552d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline\n",
        "\n",
        "# Descargar recursos de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Cargar el conjunto de datos desde Google Drive\n",
        "file_path = '/content/drive/MyDrive/procesamiento de datos/products.csv'  # Ruta correcta\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ver las primeras filas del DataFrame y las columnas disponibles\n",
        "print(df.head())\n",
        "print(\"Columnas disponibles:\", df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LlVF3NFcP_J",
        "outputId": "9483d2f4-be59-4a85-fa8f-4960ea12ec01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_id                                       product_name  aisle_id  \\\n",
            "0           1                         Chocolate Sandwich Cookies        61   \n",
            "1           2                                   All-Seasons Salt       104   \n",
            "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
            "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
            "4           5                          Green Chile Anytime Sauce         5   \n",
            "\n",
            "   department_id  \n",
            "0             19  \n",
            "1             13  \n",
            "2              7  \n",
            "3              1  \n",
            "4             13  \n",
            "Columnas disponibles: Index(['product_id', 'product_name', 'aisle_id', 'department_id'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para limpiar el texto (eliminar caracteres especiales, convertir a minúsculas)\n",
        "def clean_and_tokenize(text):\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    text = re.sub(r'[^a-záéíóúüñ\\s]', '', text)  # Eliminar caracteres especiales\n",
        "    words = word_tokenize(text)  # Tokenización\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "    return [word for word in words if word not in stop_words]\n",
        "\n",
        "# Aplicar limpieza y tokenización\n",
        "df['tokens'] = df['product_name'].apply(clean_and_tokenize)\n",
        "\n",
        "# Función para hacer stemming\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "def apply_stemming(tokens):\n",
        "    return [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "# Aplicar stemming a los tokens\n",
        "df['stemmed_tokens'] = df['tokens'].apply(apply_stemming)\n",
        "\n",
        "# Mostrar las primeras filas para verificar el preprocesamiento\n",
        "print(df[['product_name', 'tokens', 'stemmed_tokens']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuX4kgancakh",
        "outputId": "97e673f4-021c-4e86-fe14-ebf5de2a9391"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        product_name  \\\n",
            "0                         Chocolate Sandwich Cookies   \n",
            "1                                   All-Seasons Salt   \n",
            "2               Robust Golden Unsweetened Oolong Tea   \n",
            "3  Smart Ones Classic Favorites Mini Rigatoni Wit...   \n",
            "4                          Green Chile Anytime Sauce   \n",
            "\n",
            "                                              tokens  \\\n",
            "0                     [chocolate, sandwich, cookies]   \n",
            "1                                 [allseasons, salt]   \n",
            "2         [robust, golden, unsweetened, oolong, tea]   \n",
            "3  [smart, ones, classic, favorites, mini, rigato...   \n",
            "4                     [green, chile, anytime, sauce]   \n",
            "\n",
            "                                      stemmed_tokens  \n",
            "0                        [chocolat, sandwich, cooki]  \n",
            "1                                 [allseasons, salt]  \n",
            "2             [robust, gold, unsweeten, oolong, tea]  \n",
            "3  [smart, ones, classic, favorit, mini, rigatoni...  \n",
            "4                          [gre, chil, anytim, sauc]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Método de vectorización (usaremos TfidfVectorizer para este ejemplo)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')  # Usar stopwords en inglés\n",
        "X = vectorizer.fit_transform(df['product_name'])\n",
        "\n",
        "# Ver el tamaño de la matriz resultante\n",
        "print(f\"Tamaño de la matriz de características (documentos x características): {X.shape}\")\n",
        "\n",
        "# Análisis de sentimiento usando SentimentIntensityAnalyzer de NLTK\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Función para obtener el puntaje de sentimiento\n",
        "def get_sentiment(text):\n",
        "    sentiment_score = sia.polarity_scores(text)\n",
        "    return sentiment_score['compound']  # Devuelve el puntaje de sentimiento\n",
        "\n",
        "# Aplicar el análisis de sentimiento\n",
        "df['sentiment_score'] = df['product_name'].apply(get_sentiment)\n",
        "\n",
        "# Etiquetar las reseñas según el puntaje de sentimiento\n",
        "df['sentiment_label'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
        "\n",
        "# Mostrar las primeras filas con los resultados del análisis de sentimiento\n",
        "print(df[['product_name', 'sentiment_score', 'sentiment_label']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtlx7qfmdEs4",
        "outputId": "5b7fe7ac-9905-4d34-b448-e2431cb37238"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de la matriz de características (documentos x características): (49688, 10598)\n",
            "                                        product_name  sentiment_score  \\\n",
            "0                         Chocolate Sandwich Cookies           0.0000   \n",
            "1                                   All-Seasons Salt           0.0000   \n",
            "2               Robust Golden Unsweetened Oolong Tea           0.3400   \n",
            "3  Smart Ones Classic Favorites Mini Rigatoni Wit...           0.6705   \n",
            "4                          Green Chile Anytime Sauce           0.0000   \n",
            "\n",
            "  sentiment_label  \n",
            "0         neutral  \n",
            "1         neutral  \n",
            "2        positive  \n",
            "3        positive  \n",
            "4         neutral  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Función rápida para análisis de sentimiento con TextBlob\n",
        "def simple_sentiment_analysis(text):\n",
        "    analysis = TextBlob(text)\n",
        "    # Determina el sentimiento: positivo si la polaridad es mayor que 0, negativo si es menor\n",
        "    return 'POSITIVE' if analysis.sentiment.polarity > 0 else 'NEGATIVE'\n",
        "\n",
        "# Aplicar análisis de sentimiento rápido\n",
        "df['simple_sentiment'] = df['product_name'].apply(simple_sentiment_analysis)\n",
        "\n",
        "# Mostrar las primeras filas con el análisis de sentimiento\n",
        "print(df[['product_name', 'simple_sentiment']].head())\n",
        "\n",
        "# Resumen de las estadísticas de sentimiento\n",
        "sentiment_summary = df['simple_sentiment'].value_counts()\n",
        "\n",
        "# Mostrar un reporte con la distribución de sentimientos\n",
        "print(\"\\nReporte de Análisis de Sentimiento:\")\n",
        "print(f\"Sentimiento general en los nombres de productos:\\n{sentiment_summary}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MziU_AGVd3DY",
        "outputId": "7547487a-34b1-4773-cf6c-de14b39b912b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        product_name simple_sentiment\n",
            "0                         Chocolate Sandwich Cookies         NEGATIVE\n",
            "1                                   All-Seasons Salt         NEGATIVE\n",
            "2               Robust Golden Unsweetened Oolong Tea         POSITIVE\n",
            "3  Smart Ones Classic Favorites Mini Rigatoni Wit...         POSITIVE\n",
            "4                          Green Chile Anytime Sauce         NEGATIVE\n",
            "\n",
            "Reporte de Análisis de Sentimiento:\n",
            "Sentimiento general en los nombres de productos:\n",
            "simple_sentiment\n",
            "NEGATIVE    36854\n",
            "POSITIVE    12834\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}